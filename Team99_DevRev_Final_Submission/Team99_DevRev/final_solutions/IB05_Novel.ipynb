{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Hi_3GrtnQwI","executionInfo":{"status":"ok","timestamp":1702295500038,"user_tz":-330,"elapsed":127766,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"427c615a-6f8e-4fd9-b0bf-1681abadba53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai==0.28\n","  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/76.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n","Installing collected packages: openai\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed openai-0.28.0\n","Mon Dec 11 11:49:38 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   51C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Collecting ctransformers\n","  Downloading ctransformers-0.2.27.tar.gz (376 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.19.4)\n","Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2023.11.17)\n","Building wheels for collected packages: ctransformers\n","  Building wheel for ctransformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ctransformers: filename=ctransformers-0.2.27-cp310-cp310-linux_x86_64.whl size=2338834 sha256=7e649322785a6e894a4d63b7f889e35f49c8c8e4b91f613cfc59a00b7902050f\n","  Stored in directory: /root/.cache/pip/wheels/dd/54/e9/32364da8eee84a2b0b412394983c15add18816c507e90f02d8\n","Successfully built ctransformers\n","Installing collected packages: ctransformers\n","Successfully installed ctransformers-0.2.27\n"]}],"source":["''' This notebook contains the following:\n","    M1 - GPT 3.5 Finetuned on the new tool prompts\n","    M2 - GPT 3.5\n","\n","    Following tools have been added:\n","    'get_previous_sprint':'Returns the sprint id of the previous sprint',\n","    'return_top_k_items':'Returns the top k items from the given list of items',\n","'''\n","!pip install openai==0.28\n","!nvidia-smi\n","!pip install pandas\n","!CT_CUBLAS=1 pip install ctransformers --no-binary ctransformers"]},{"cell_type":"code","source":["!pip install accelerate\n","!pip install -U git+https://github.com/huggingface/accelerate.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92ZS1oVUnXGY","executionInfo":{"status":"ok","timestamp":1702295526197,"user_tz":-330,"elapsed":26179,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"df359436-fa19-47db-9425-0e3ff1cf4b8d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/265.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m225.3/265.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.25.0\n","Collecting git+https://github.com/huggingface/accelerate.git\n","  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-d9qt00wc\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-d9qt00wc\n","  Resolved https://github.com/huggingface/accelerate.git to commit 694f2e2c12efbda81a1aa4b4b486767264116a2f\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0.dev0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0.dev0) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.25.0.dev0) (1.3.0)\n","Building wheels for collected packages: accelerate\n","  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for accelerate: filename=accelerate-0.25.0.dev0-py3-none-any.whl size=267070 sha256=d6dc2f75d9656e02b6a13a46e4eabd61d4b2296d0cf4a8748665f61d5cb3e243\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-1spp0e90/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n","Successfully built accelerate\n","Installing collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.25.0\n","    Uninstalling accelerate-0.25.0:\n","      Successfully uninstalled accelerate-0.25.0\n","Successfully installed accelerate-0.25.0.dev0\n"]}]},{"cell_type":"code","source":["!pip install pytorch-pretrained-bert\n","import pytorch_pretrained_bert as ppb\n","assert 'bert-large-cased' in ppb.modeling.PRETRAINED_MODEL_ARCHIVE_MAP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kcf7JIICoiPJ","executionInfo":{"status":"ok","timestamp":1702295540121,"user_tz":-330,"elapsed":13949,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"c76922a6-32cf-4f56-9f26-8faad4620186"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m122.9/123.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.1.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.23.5)\n","Collecting boto3 (from pytorch-pretrained-bert)\n","  Downloading boto3-1.33.11-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.66.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2023.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.1.0)\n","Collecting botocore<1.34.0,>=1.33.11 (from boto3->pytorch-pretrained-bert)\n","  Downloading botocore-1.33.11-py3-none-any.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.9.0,>=0.8.2 (from boto3->pytorch-pretrained-bert)\n","  Downloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2023.11.17)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.11->boto3->pytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.11->boto3->pytorch-pretrained-bert) (1.16.0)\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","Successfully installed boto3-1.33.11 botocore-1.33.11 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.8.2\n"]}]},{"cell_type":"code","source":["!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n","!pip install -q datasets bitsandbytes einops wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_lJl9DdomgC","executionInfo":{"status":"ok","timestamp":1702295575089,"user_tz":-330,"elapsed":34973,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"9c51e619-17dd-40ee-8444-5b7b3a1d0465"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import openai\n","import os\n","import pandas as pd"],"metadata":{"id":"RoGX6DrUornK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sheet_id = \"1N8oZ6XYKFeWbAwTr13yCSxbKu6eo-iKsYH3-IJ5Uuuk\"\n","sheet_name = \"Sheet1\"\n","url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\""],"metadata":{"id":"74sOfxmXd29h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.read_csv(url)"],"metadata":{"id":"aAeUhx00etES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["queries=[] # This list will contain the list of all queries\n","for query in df['Prompt']:\n","  queries.append(query)"],"metadata":{"id":"yhI_GSeBuItq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["openai.api_key=\"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\"\n","model1=\"ft:gpt-3.5-turbo-0613:devrev-inter-iit-tech-meet::8UUzm0Kh\""],"metadata":{"id":"zwHWZGeupY3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_tools(query):\n","  system_prompt = \"\"\" Find the tools that would be useful to answer the following query. The available tools and their uses are as follows:\n","  [\n","    'works_list':'returns a list of work-items matching the request',\n","    'summarize_objects':'summarizes a list of objects',\n","    'prioritize_objects':'sorts a list of objects by priority',\n","    'add_work_items_to_sprint':'Adds given work items to a sprint',\n","    'get_sprint_id':'Returns id of the current sprint',\n","    'get_similar_work_items':'Returns work items similar to the given work item',\n","    'search_object_by_name':'given a string, returns id of a matching object',\n","    'create_actionable_tasks_from_text':'Given a text, extracts actionable tasks',\n","    'who_am_i':'Returns id of the current user',\n","  ]\n","  Your answer should only compose of one or more of these tools. Any extra tool or text will be penalized. Return the tools enclosed in [ ].\n","  Given query is \"\"\"\n","\n","  user_prompt = f\"\"\": {query} : \"\"\"\n","\n","  final_prompt = system_prompt + \"\\n\" + user_prompt\n","  messages=[{\n","      \"role\":\"user\",\n","      \"content\":final_prompt\n","  }]\n","\n","  responses=openai.ChatCompletion.create(\n","      model=model1,\n","      messages=messages,\n","      temperature=0\n","  )\n","\n","  return responses.choices[0].message['content']"],"metadata":{"id":"_NiKiGf4ot_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tool_results=[]\n","for query in queries:\n","  input_string=get_tools(query)\n","  tool_results.append(input_string)"],"metadata":{"id":"46lTaUffpsOt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Conversion of string to list:\n","def convert_string_to_list(string):\n","  \"\"\"\n","  Converts a string in the format of a list to a list of strings.\n","\n","  Args:\n","    string: The string to convert.\n","\n","  Returns:\n","    A list of strings.\n","  \"\"\"\n","  # Remove any leading and trailing spaces\n","  string = string.strip()\n","\n","  # Check if the string starts and ends with square brackets\n","  if not string.startswith('[') or not string.endswith(']'):\n","    raise ValueError('Invalid string format. Expected format: [item1, item2, ...]')\n","\n","  # Remove the square brackets\n","  string = string[1:-1]\n","\n","  # Split the string by commas and strip any whitespace around each item\n","  items = [item.strip() for item in string.split(',')]\n","\n","  return items"],"metadata":{"id":"401kg-RvqP7S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analyze_query(tools_list, query_text):\n","    tools_purpose = {\n","        'works_list': 'Returns a list of objects matching the request',\n","        'summarize_objects': 'Summarizes a list of objects',\n","        'prioritize_objects': 'Returns a list of objects sorted by priority',\n","        'add_work_items_to_sprint':'Adds the given objects to the sprint',\n","        'get_sprint_id':'Return the id of the current sprint',\n","        'get_similar_work_items':'Returns a list of objects that are similar to the given object',\n","        'search_object_by_name':'Given a search string, returns the id of a matching object in the system of record',\n","        'create_actionable_tasks_from_text':'Given a text, extracts actionable text The text from which the actionable string insights, and creates tasks for them, which are kind of a work item',\n","        'who_am_i':'Returns string_id of current user',\n","        # 'get_previous_sprint':'Returns the sprint id of the previous sprint',\n","        # 'return_top_k_items':'Returns the top k items from the given list of items',\n","    }\n","\n","    tools_arguments = {\n","        'works_list': ['applies_to_part: Array of strings to filter works relevant to', 'created_by: Takes array of strings and filters work created by users in the array', 'issue.priority: Array of strings to filter issues with given priorites in the array', 'issue.rev_orgs: Array of strings to filter issues for the organizations provided in the array', 'limit: integer providing the maximum number of works to return', 'owned_by: Array of strings to filter issues owned by users specified in the array', 'stage.name: Array of strings to filter work in the stages provided in the array', 'ticket.needs_response: Boolean value telling if a ticket needs a response','ticket.rev_org: Array of strings to return tickets associated with the given strings', 'ticket.severity: Array of strings to filter issues with given severity in the array', 'ticket.source_channel: Array of strings to filter for ticklets of the provided channels in the array', 'type: Array of strings with allowed values: [issue, ticket, task] Filters for work of the provided types' ],\n","        'summarize_objects': ['objects: List of object ids to summarize'],\n","        'prioritize_objects': ['objects: List of objects to prioritize'],\n","        'add_work_items_to_sprint': ['work_ids: List of objects to be added', 'sprint_id: Id of the sprint'],\n","        'get_sprint_id': [],\n","        'get_similar_work_items': ['work_id: id of work item to find similar items to'],\n","        'search_object_by_name': ['query: String to search for'],\n","        'create_actionable_tasks_from_text': ['text: Text to create actionable tasks from'],\n","        'who_am_i': [],\n","        # 'get_previous_sprint':[],\n","        # 'return_top_k_items':['objects: List of objects sorted by priority', 'k: Number of items to be returned']\n","    }\n","\n","    relevant_purposes = {tool: tools_purpose[tool] for tool in tools_list if tool in tools_purpose}\n","    relevant_arguments = {tool: tools_arguments[tool] for tool in tools_list if tool in tools_arguments}\n","\n","    output_string = f\"The given query utilizes the following tools: {tools_list}. \"\n","    output_string += f\"The arguments of the tools and their description  is as follows. Format is 'argument_name:Purpose of argument': {relevant_arguments}. \"\n","    output_string += f\"The purpose of the tools is as follows: {relevant_purposes}. \"\n","    output_string +=\"Note that the words issues, objects and work_items have been used interchangably\"\n","    output_string += f\"Find the values arguments for the given tools from the following text:\\\\ {query_text} \\\\\"\n","    output_string += \"Just return the value of the arguments, do not return anything else. In case you need to use the output of the previous tool as an input to the next tool, you can name it as $$PREV[i], where i is the index of the tool starting from 0. Return answer in nested JSON format with separate JSONS in one JSON for each tool named after the tool itself. The keys are: argument_name and argument_value. Every argument need not have a value. But every tool taking an argument must take atleast one argument. Only find values for relevant arguments.\"\n","\n","    return output_string"],"metadata":{"id":"EDtsSJ01q1Hd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arg_prompts=[]\n","for i in range(0,len(tool_results)):\n","  # convert string to list of tools\n","  tools_list=convert_string_to_list(tool_results[i])\n","  final_prompt=analyze_query(tools_list,queries[i]);\n","  arg_prompts.append(final_prompt)"],"metadata":{"id":"MDVbii9RrBim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2 = \"gpt-3.5-turbo\""],"metadata":{"id":"JSYzLtjWoTWt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_arguments(formatted_prompt):\n","  messages=[{\n","      \"role\":\"user\",\n","      \"content\":formatted_prompt\n","  }]\n","\n","  responses=openai.ChatCompletion.create(\n","      model=model2,\n","      messages=messages,\n","      temperature=0\n","  )\n","\n","  return responses.choices[0].message['content']"],"metadata":{"id":"jOEng54krVim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["argument_predictions=[]\n","for prompt in arg_prompts:\n","  arg=get_arguments(prompt);\n","  argument_predictions.append(arg)"],"metadata":{"id":"TiHlwGS-rgSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for arg in argument_predictions:\n","  print(arg)\n","  print('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AC2Ue00ewvi0","executionInfo":{"status":"ok","timestamp":1702295702830,"user_tz":-330,"elapsed":23,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"6866673c-7a68-40dc-b009-76d9011518da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"don:core:dvrv-us-1:devo/0:issue/1\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"created_by\": [\"Jane Doe\"],\n","    \"type\": [\"user story\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"type\": [\"task\"],\n","    \"stage.name\": [\"current sprint\"],\n","    \"limit\": 0\n","  }\n","}\n","\n","\n","{\n","  \"get_sprint_id\": {},\n","  \"works_list\": {\n","    \"stage.name\": [\"$$PREV[0].name\"],\n","    \"type\": [\"issue\"],\n","    \"issue.tags\": [\"Security\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1].ids\"]\n","  },\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Recommend actions to resolve the issues\"\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"type\": [\"task\"],\n","    \"stage.name\": [\"current sprint\"],\n","    \"ticket.source_channel\": [\"UI/UX\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"DEV\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": \"$$PREV[0]\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"issue.rev_orgs\": [\"Internal\"],\n","    \"type\": [\"task\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Given a customer transcript \\\"text\\\", create work items, add them to the current sprint, summarize and prioritize them\"\n","  },\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": \"$$PREV[0].actionable_tasks\",\n","    \"sprint_id\": \"$$PREV[1].sprint_id\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": \"$$PREV[1].work_ids\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": \"$$PREV[2].objects\"\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"user/ref:issue\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"argument_name\": \"query\",\n","    \"argument_value\": \"P0\"\n","  },\n","  \"get_similar_work_items\": {\n","    \"argument_name\": \"work_id\",\n","    \"argument_value\": \"$$PREV[0]\"\n","  },\n","  \"summarize_objects\": {\n","    \"argument_name\": \"objects\",\n","    \"argument_value\": \"$$PREV[1]\"\n","  },\n","  \"prioritize_objects\": {\n","    \"argument_name\": \"objects\",\n","    \"argument_value\": \"$$PREV[2]\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"Mark\"\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"$$PREV[0]\"],\n","    \"sprint_id\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"rev organization SigmaSquad\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"created_by\": [\"my_username\"],\n","    \"limit\": 100\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0].works_list\"]\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"\"\n","  },\n","  \"works_list\": {\n","    \"stage.name\": [\"triage\"],\n","    \"issue.rev_orgs\": [\"Ajin\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1]\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[2]\"]\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Given the text T detailing the recent team meeting, create a list of tasks.\"\n","  },\n","  \"works_list\": {\n","    \"ticket.source_channel\": [\"discord\"],\n","    \"ticket.rev_org\": [\"Raja\"]\n","  },\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": \"$$PREV[0]\",\n","    \"sprint_id\": \"current\"\n","  }\n","}\n","\n","\n","{\n","  \"summarize_objects\": {\n","    \"objects\": [\"Backend\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"get_sprint_id\": {},\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Delve into the cosmic ponderings: Explore and compare diverse cultural and scientific perspectives on the question, \\\"What is the nature of existence?\\\"\"\n","  },\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"\"\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"BUG-456\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[1]\"]\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"REV(customer) N V\"\n","  },\n","  \"works_list\": {\n","    \"issue.rev_orgs\": [\"REV(customer) N V\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1]\"]\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"applies_to_part\": [\"minutes\"],\n","    \"type\": [\"issue\"]\n","  },\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Analyze the minutes from the latest team meeting, generate a task list\"\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"$$PREV[1]\"],\n","    \"sprint_id\": \"current\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"Analytics\"\n","  },\n","  \"works_list\": {\n","    \"applies_to_part\": [\"$$PREV[0]\"],\n","    \"type\": [\"task\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1]\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[2]\"]\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Reflect on the concept of time\"\n","  },\n","  \"get_similar_work_items\": {}\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"Microsoft Teams\"\n","  },\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"$$PREV[0]\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Contemplate the meaning of knowledge\"\n","  }\n","}\n","\n","\n","{\n","  \"who_am_i\": {},\n","  \"works_list\": {\n","    \"ticket.severity\": [\"high\"],\n","    \"ticket.rev_org\": [\"me\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1].result\"]\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"urgent emails\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"send an email to admin about the problems encountered during completion of tasks\"\n","  },\n","  \"search_object_by_name\": {\n","    \"query\": \"admin\"\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"Null Pointer Exception in Module\"\n","  },\n","  \"search_object_by_name\": {\n","    \"query\": \"Null Pointer Exception\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"Backend Refactoring\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"$$PREV[0]\"],\n","    \"sprint_id\": \"$$PREV[2]\"\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Implement the payment gateway and test the checkout flow\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"$$PREV[1]\"],\n","    \"sprint_id\": \"current_sprint_id\"\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"API Development\"\n","  },\n","  \"search_object_by_name\": {\n","    \"query\": \"API Development\"\n","  }\n","}\n","\n","\n","{\n","  \"who_am_i\": {},\n","  \"works_list\": {\n","    \"type\": [\"task\"],\n","    \"owned_by\": [\"$$PREV[0].who_am_i\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1].works_list\"]\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"Oppenheimer\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"30 tickets coming in from Gemini through email, which were assigned to me, that need a response\"\n","  },\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"$$PREV[0]\"\n","  },\n","  \"who_am_i\": {}\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"applies_to_part\": [\"INS69\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"Navishkar\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"$$PREV[1]\"],\n","    \"sprint_id\": \"current\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"\"\n","  },\n","  \"works_list\": {\n","    \"ticket.severity\": [\"blocker\"],\n","    \"ticket.rev_org\": [\"Llama\"],\n","    \"issue.priority\": [\"P0\"],\n","    \"issue.rev_orgs\": [\"Falcon\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1]\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[2]\"]\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"Finetuning GPT-3.5-Turbo\"\n","  }\n","}\n","\n","\n","{\n","  \"who_am_i\": {},\n","  \"works_list\": {\n","    \"owned_by\": [\"me\"],\n","    \"type\": [\"task\"],\n","    \"ticket.needs_response\": true\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"$$PREV[1]\"],\n","    \"sprint_id\": \"$$PREV[2]\"\n","  },\n","  \"search_object_by_name\": {\n","    \"query\": \"URGENT\"\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Send an email to the IT department detailing recent technical challenges faced during project completion and request assistance.\"\n","  },\n","  \"works_list\": {\n","    \"type\": [\"issue\", \"ticket\"],\n","    \"ticket.source_channel\": [\"email\"]\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"finance meeting\"\n","  }\n","}\n","\n","\n","{\n","  \"summarize_objects\": {\n","    \"objects\": [\"P1 issues\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"P1 issues\"]\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"P1 issues\"],\n","    \"sprint_id\": \"ongoing sprint\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"Microsoft Team\"\n","  },\n","  \"works_list\": {\n","    \"applies_to_part\": [\"Microsoft Team\", \"Zoom\"]\n","  },\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"$$PREV[1]\", \"$$PREV[2]\"],\n","    \"sprint_id\": \"sprint_id_value\"\n","  }\n","}\n","\n","\n","{\n","  \"[]\": {\n","    \"argument_name\": \"None\",\n","    \"argument_value\": \"None\"\n","  }\n","}\n","\n","\n","{\n","  \"[]\": {\n","    \"argument_name\": \"N/A\",\n","    \"argument_value\": \"N/A\"\n","  }\n","}\n","\n","\n","{\n","  \"summarize_objects\": {\n","    \"objects\": []\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": []\n","  },\n","  \"search_object_by_name\": {\n","    \"query\": \"Pinnacle\"\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"User Story:123\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1]\"]\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"applies_to_part\": [\"Inter IIT Tech Meet 12.0\"]\n","  },\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": [\"$$PREV[0].objects\"],\n","    \"sprint_id\": \"sprint_id_value\"\n","  }\n","}\n","\n","\n"]}]},{"cell_type":"code","source":["''' Now, we have 3 lists: queries, tool_results and argument_predictions.\n","We can summarize them into a CSV '''\n","data={'query':queries, 'tools':tool_results, 'arguments':argument_predictions}\n","df=pd.DataFrame(data)\n","df.to_csv('resultFinetunedIB05_base.csv')"],"metadata":{"id":"M3lwFpFcvxAZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_json_schema(cell_value):\n","    prompt = \"\"\"Convert the following argument cell value to the general JSON schema. If there are specific fields not present. Ignore them.\n","                  general JSON schema (results may be different):\n","                  [\n","                    \"tool_name\": \"tool_name\",\n","                    \"arguments\": [\n","                      {\n","                        \"argument_name\":\"arg_name\"\n","                        \"argument_value\":\"arg_value\"\n","                      }\n","                    ]\n","                  ]\n","\n","                  An example:\n","                  [\n","                    {\n","                      \"tool_name\": \"whoami\",\n","                      \"arguments\": []\n","                    },\n","                    {\n","                      \"tool_name\": \"works_list\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"issue.priority\",\n","                          \"argument_value\": [\"p0\"]\n","                        },\n","                        {\n","                          \"argument_name\": \"owned_by\",\n","                          \"argument_value\": [\"$$PREV[0]\"]\n","                        },\n","                        {\n","                          \"argument_name\": \"type\",\n","                          \"argument_value\": [\"issue\"]\n","                        }\n","                      ]\n","                    },\n","                    {\n","                      \"tool_name\": \"prioritize_objects\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"objects\",\n","                          \"argument_value\": \"$$PREV[1]\"\n","                        }\n","                      ]\n","                    },\n","                    {\n","                      \"tool_name\": \"get_sprint_id\",\n","                      \"arguments\": []\n","                    },\n","                    {\n","                      \"tool_name\": \"add_work_items_to_sprint\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"work_ids\",\n","                          \"argument_value\": \"$$PREV[2]\"\n","                        },\n","                        {\n","                          \"argument_name\": \"sprint_id\",\n","                          \"argument_value\": \"$$PREV[3]\"\n","                        }\n","                      ]\n","                    }\n","                ]\"\"\"\n","    messages=[{\n","      \"role\":\"user\",\n","      \"content\":prompt\n","  }]\n","\n","    response=openai.ChatCompletion.create(\n","      model=model,\n","      messages=messages,\n","      temperature=0\n","  )\n","    generated_json_schema = response.choices[0].message['content']\n","\n","    return generated_json_schema\n","\n","csv_file_path = '/content/resultIB05_novel.csv'\n","df = pd.read_csv(csv_file_path)\n","\n","df['generated_json_schema'] = df['arguments'].apply(generate_json_schema)\n","\n","output_csv_path = 'output_file.csv'\n","df.to_csv(output_csv_path, index=False)"],"metadata":{"id":"XJLk3iSKv7Vr"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}