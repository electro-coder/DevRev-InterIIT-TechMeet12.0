{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLpHZtx7DmBu","executionInfo":{"status":"ok","timestamp":1702223229333,"user_tz":-330,"elapsed":133090,"user":{"displayName":"CS21B033 MARUVADA VENKATA SRIRAMAKRISHNA KARTHIKEYA","userId":"16433091511850008447"}},"outputId":"35419950-5964-46a6-9d7f-0c8c4199b186"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai==0.28\n","  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n","Installing collected packages: openai\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed openai-0.28.0\n","Sun Dec 10 15:45:02 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Collecting ctransformers\n","  Downloading ctransformers-0.2.27.tar.gz (376 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.19.4)\n","Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2023.11.17)\n","Building wheels for collected packages: ctransformers\n","  Building wheel for ctransformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ctransformers: filename=ctransformers-0.2.27-cp310-cp310-linux_x86_64.whl size=2338842 sha256=938899452f4be0ada972cc3dfc4a6145714f7fee1c41480fe75bde52ed662eba\n","  Stored in directory: /root/.cache/pip/wheels/dd/54/e9/32364da8eee84a2b0b412394983c15add18816c507e90f02d8\n","Successfully built ctransformers\n","Installing collected packages: ctransformers\n","Successfully installed ctransformers-0.2.27\n"]}],"source":["''' This notebook contains the following:\n","    M1 - GPT 3.5 finetuned\n","    M2 - GPT 4\n","'''\n","!pip install openai==0.28\n","!nvidia-smi\n","!pip install pandas\n","!CT_CUBLAS=1 pip install ctransformers --no-binary ctransformers"]},{"cell_type":"code","source":["!pip install accelerate\n","!pip install -U git+https://github.com/huggingface/accelerate.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JWqxd9e2DrTg","executionInfo":{"status":"ok","timestamp":1702223252709,"user_tz":-330,"elapsed":23392,"user":{"displayName":"CS21B033 MARUVADA VENKATA SRIRAMAKRISHNA KARTHIKEYA","userId":"16433091511850008447"}},"outputId":"123a475a-08fd-4495-b203-3431d5ccfa2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting accelerate\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.25.0\n","Collecting git+https://github.com/huggingface/accelerate.git\n","  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-cgim__nk\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-cgim__nk\n","  Resolved https://github.com/huggingface/accelerate.git to commit 9964f90fd7d50577998a22f3dba8590e644d255b\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0.dev0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0.dev0) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.25.0.dev0) (1.3.0)\n","Building wheels for collected packages: accelerate\n","  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for accelerate: filename=accelerate-0.25.0.dev0-py3-none-any.whl size=267070 sha256=38318d5a67a8b4e69b51e3a15895502dd82944a5a4ef6c73b24248edc90dad4d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-iy86so8u/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n","Successfully built accelerate\n","Installing collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.25.0\n","    Uninstalling accelerate-0.25.0:\n","      Successfully uninstalled accelerate-0.25.0\n","Successfully installed accelerate-0.25.0.dev0\n"]}]},{"cell_type":"code","source":["!pip install pytorch-pretrained-bert\n","import pytorch_pretrained_bert as ppb\n","assert 'bert-large-cased' in ppb.modeling.PRETRAINED_MODEL_ARCHIVE_MAP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eXC28g24Dt8V","executionInfo":{"status":"ok","timestamp":1702223269731,"user_tz":-330,"elapsed":17044,"user":{"displayName":"CS21B033 MARUVADA VENKATA SRIRAMAKRISHNA KARTHIKEYA","userId":"16433091511850008447"}},"outputId":"ba6c3cb4-2898-425b-fa1e-29e728ec54e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pytorch-pretrained-bert\n","  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.1.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.23.5)\n","Collecting boto3 (from pytorch-pretrained-bert)\n","  Downloading boto3-1.33.11-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.66.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2023.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.1.0)\n","Collecting botocore<1.34.0,>=1.33.11 (from boto3->pytorch-pretrained-bert)\n","  Downloading botocore-1.33.11-py3-none-any.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->pytorch-pretrained-bert)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.9.0,>=0.8.2 (from boto3->pytorch-pretrained-bert)\n","  Downloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2023.11.17)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.11->boto3->pytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.11->boto3->pytorch-pretrained-bert) (1.16.0)\n","Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n","Successfully installed boto3-1.33.11 botocore-1.33.11 jmespath-1.0.1 pytorch-pretrained-bert-0.6.2 s3transfer-0.8.2\n"]}]},{"cell_type":"code","source":["!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n","!pip install -q datasets bitsandbytes einops wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"am77mKbLDwKk","executionInfo":{"status":"ok","timestamp":1702223304513,"user_tz":-330,"elapsed":34811,"user":{"displayName":"CS21B033 MARUVADA VENKATA SRIRAMAKRISHNA KARTHIKEYA","userId":"16433091511850008447"}},"outputId":"570ca6da-e107-4432-a119-39ec8f9c3e39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.9/133.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import openai\n","import os\n","import pandas as pd"],"metadata":{"id":"oqlsAPhbDyvM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["queries=['Summarize work items similar to don:core:dvrv-us-1:devo/0:issue/1', 'Summarize and prioritize issues of P0 for user Harry '] # This list will contain the list of all queries\n"],"metadata":{"id":"JxsQZFoED0xd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["openai.api_key=\"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\"\n","model1=\"ft:gpt-3.5-turbo-0613:devrev-inter-iit-tech-meet::8UG8JMbv\""],"metadata":{"id":"1OFUIphbD2Vs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Model-1 gpt-3.5"],"metadata":{"id":"PSDitAXMEB2y"}},{"cell_type":"code","source":["def get_tools(query):\n","  system_prompt = \"\"\" Find the tools that would be useful to answer the following query. The available tools and their uses are as follows:\n","  [\n","    'works_list':'returns a list of work-items matching the request',\n","    'summarize_objects':'summarizes a list of objects',\n","    'prioritize_objects':'sorts a list of objects by priority',\n","    'add_work_items_to_sprint':'Adds given work items to a sprint',\n","    'get_sprint_id':'Returns id of the current sprint',\n","    'get_similar_work_items':'Returns work items similar to the given work item',\n","    'search_object_by_name':'given a string, returns id of a matching object',\n","    'create_actionable_tasks_from_text':'Given a text, extracts actionable tasks',\n","    'who_am_i':'Returns id of the current user',\n","  ]\n","  Your answer should only compose of one or more of these tools. Any extra tool or text will be penalized. Return the tools enclosed in [ ].\n","  Given query is \"\"\"\n","\n","  user_prompt = f\"\"\": {query} : \"\"\"\n","\n","  final_prompt = system_prompt + \"\\n\" + user_prompt\n","  messages=[{\n","      \"role\":\"user\",\n","      \"content\":final_prompt\n","  }]\n","\n","  responses=openai.ChatCompletion.create(\n","      model=model1,\n","      messages=messages,\n","      temperature=0\n","  )\n","\n","  return responses.choices[0].message['content']"],"metadata":{"id":"H4DW7nOjEHDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# unit testing of get_tools function:\n","tool_results=[]\n","for query in queries:\n","  input_string=get_tools(query)\n","  tool_results.append(input_string)"],"metadata":{"id":"7V1MRxw4EOaw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_string_to_list(string):\n","  \"\"\"\n","  Converts a string in the format of a list to a list of strings.\n","\n","  Args:\n","    string: The string to convert.\n","\n","  Returns:\n","    A list of strings.\n","  \"\"\"\n","  # Remove any leading and trailing spaces\n","  string = string.strip()\n","\n","  # Check if the string starts and ends with square brackets\n","  if not string.startswith('[') or not string.endswith(']'):\n","    raise ValueError('Invalid string format. Expected format: [item1, item2, ...]')\n","\n","  # Remove the square brackets\n","  string = string[1:-1]\n","\n","  # Split the string by commas and strip any whitespace around each item\n","  items = [item.strip() for item in string.split(',')]\n","\n","  return items"],"metadata":{"id":"zfzJ2rohEPGf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analyze_query(tools_list, query_text):\n","    tools_purpose = {\n","        'works_list': 'Returns a list of objects matching the request',\n","        'summarize_objects': 'Summarizes a list of objects',\n","        'prioritize_objects': 'Returns a list of objects sorted by priority',\n","        'add_work_items_to_sprint':'Adds the given objects to the sprint',\n","        'get_sprint_id':'Return the id of the current sprint',\n","        'get_similar_work_items':'Returns a list of objects that are similar to the given object',\n","        'search_object_by_name':'Given a search string, returns the id of a matching object in the system of record',\n","        'create_actionable_tasks_from_text':'Given a text, extracts actionable text The text from which the actionable string insights, and creates tasks for them, which are kind of a work item',\n","        'who_am_i':'Returns string_id of current user'\n","    }\n","\n","    tools_arguments = {\n","        'works_list': ['applies_to_part: Array of strings to filter works relevant to', 'created_by: Takes array of strings and filters work created by users in the array', 'issue.priority: Array of strings to filter issues with given priorites in the array', 'issue.rev_orgs: Array of strings to filter issues for the organizations provided in the array', 'limit: integer providing the maximum number of works to return', 'owned_by: Array of strings to filter issues owned by users specified in the array', 'stage.name: Array of strings to filter work in the stages provided in the array', 'ticket.needs_response: Boolean value telling if a ticket needs a response','ticket.rev_org: Array of strings to return tickets associated with the given strings', 'ticket.severity: Array of strings to filter issues with given severity in the array', 'ticket.source_channel: Array of strings to filter for ticklets of the provided channels in the array', 'type: Array of strings with allowed values: [issue, ticket, task] Filters for work of the provided types' ],\n","        'summarize_objects': ['objects: List of object ids to summarize'],\n","        'prioritize_objects': ['objects: List of objects to prioritize'],\n","        'add_work_items_to_sprint': ['work_ids: List of objects to be added', 'sprint_id: Id of the sprint'],\n","        'get_sprint_id': [],\n","        'get_similar_work_items': ['work_id: id of work item to find similar items to'],\n","        'search_object_by_name': ['query: String to search for'],\n","        'create_actionable_tasks_from_text': ['text: Text to create actionable tasks from'],\n","        'who_am_i': []\n","    }\n","\n","    relevant_purposes = {tool: tools_purpose[tool] for tool in tools_list if tool in tools_purpose}\n","    relevant_arguments = {tool: tools_arguments[tool] for tool in tools_list if tool in tools_arguments}\n","\n","    output_string = f\"The given query utilizes the following tools: {tools_list}. \"\n","    output_string += f\"The arguments of the tools and their description  is as follows. Format is 'argument_name:Purpose of argument': {relevant_arguments}. \"\n","    output_string += f\"The purpose of the tools is as follows: {relevant_purposes}. \"\n","    output_string +=\"Note that the words issues, objects and work_items have been used interchangably\"\n","    output_string += f\"Find the values arguments for the given tools from the following text:\\\\ {query_text} \\\\\"\n","    output_string += \"Just return the value of the arguments, do not return anything else. In case you need to use the output of the previous tool as an input to the next tool, you can name it as $$PREV[i], where i is the index of the tool starting from 0. Return answer in nested JSON format with separate JSONS in one JSON for each tool named after the tool itself. The keys are: argument_name and argument_value. Every argument need not have a value. But every tool taking an argument must take atleast one argument. Only find values for relevant arguments.\"\n","\n","    return output_string"],"metadata":{"id":"aoIaPuygERy-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arg_prompts=[]\n","for i in range(0,len(tool_results)):\n","  # convert string to list of tools\n","  tools_list=convert_string_to_list(tool_results[i])\n","  final_prompt=analyze_query(tools_list,queries[i]);\n","  arg_prompts.append(final_prompt)"],"metadata":{"id":"Zt4Dc2jQEXnP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arg_prompts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpku_f3vEZUv","executionInfo":{"status":"ok","timestamp":1702223383349,"user_tz":-330,"elapsed":4,"user":{"displayName":"CS21B033 MARUVADA VENKATA SRIRAMAKRISHNA KARTHIKEYA","userId":"16433091511850008447"}},"outputId":"71b750b1-b3eb-4c66-adad-3bf702aaa6f4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"The given query utilizes the following tools: ['get_similar_work_items', 'summarize_objects']. The arguments of the tools and their description  is as follows. Format is 'argument_name:Purpose of argument': {'get_similar_work_items': ['work_id: id of work item to find similar items to'], 'summarize_objects': ['objects: List of object ids to summarize']}. The purpose of the tools is as follows: {'get_similar_work_items': 'Returns a list of objects that are similar to the given object', 'summarize_objects': 'Summarizes a list of objects'}. Note that the words issues, objects and work_items have been used interchangablyFind the values arguments for the given tools from the following text:\\\\ Summarize work items similar to don:core:dvrv-us-1:devo/0:issue/1 \\\\Just return the value of the arguments, do not return anything else. In case you need to use the output of the previous tool as an input to the next tool, you can name it as $$PREV[i], where i is the index of the tool starting from 0. Return answer in nested JSON format with separate JSONS in one JSON for each tool named after the tool itself. The keys are: argument_name and argument_value. Every argument need not have a value. But every tool taking an argument must take atleast one argument. Only find values for relevant arguments.\",\n"," \"The given query utilizes the following tools: ['works_list', 'summarize_objects', 'prioritize_objects']. The arguments of the tools and their description  is as follows. Format is 'argument_name:Purpose of argument': {'works_list': ['applies_to_part: Array of strings to filter works relevant to', 'created_by: Takes array of strings and filters work created by users in the array', 'issue.priority: Array of strings to filter issues with given priorites in the array', 'issue.rev_orgs: Array of strings to filter issues for the organizations provided in the array', 'limit: integer providing the maximum number of works to return', 'owned_by: Array of strings to filter issues owned by users specified in the array', 'stage.name: Array of strings to filter work in the stages provided in the array', 'ticket.needs_response: Boolean value telling if a ticket needs a response', 'ticket.rev_org: Array of strings to return tickets associated with the given strings', 'ticket.severity: Array of strings to filter issues with given severity in the array', 'ticket.source_channel: Array of strings to filter for ticklets of the provided channels in the array', 'type: Array of strings with allowed values: [issue, ticket, task] Filters for work of the provided types'], 'summarize_objects': ['objects: List of object ids to summarize'], 'prioritize_objects': ['objects: List of objects to prioritize']}. The purpose of the tools is as follows: {'works_list': 'Returns a list of objects matching the request', 'summarize_objects': 'Summarizes a list of objects', 'prioritize_objects': 'Returns a list of objects sorted by priority'}. Note that the words issues, objects and work_items have been used interchangablyFind the values arguments for the given tools from the following text:\\\\ Summarize and prioritize issues of P0 for user Harry  \\\\Just return the value of the arguments, do not return anything else. In case you need to use the output of the previous tool as an input to the next tool, you can name it as $$PREV[i], where i is the index of the tool starting from 0. Return answer in nested JSON format with separate JSONS in one JSON for each tool named after the tool itself. The keys are: argument_name and argument_value. Every argument need not have a value. But every tool taking an argument must take atleast one argument. Only find values for relevant arguments.\"]"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["model2=\"gpt-4\""],"metadata":{"id":"nzlhtA-KKkw8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_arguments(formatted_prompt):\n","  messages=[{\n","      \"role\":\"user\",\n","      \"content\":formatted_prompt\n","  }]\n","\n","  responses=openai.ChatCompletion.create(\n","      model=model2,\n","      messages=messages,\n","      temperature=0\n","  )\n","\n","  return responses.choices[0].message['content']"],"metadata":{"id":"76SjFcQiEaAt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["argument_predictions=[]\n","for prompt in arg_prompts:\n","  arg=get_arguments(prompt);\n","  argument_predictions.append(arg)"],"metadata":{"id":"oiie0RHZEb_0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for arg in argument_predictions:\n","  print(arg)\n","  print('\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QQPVp8dwEdpO","executionInfo":{"status":"ok","timestamp":1702223405011,"user_tz":-330,"elapsed":463,"user":{"displayName":"CS21B033 MARUVADA VENKATA SRIRAMAKRISHNA KARTHIKEYA","userId":"16433091511850008447"}},"outputId":"618eb0ad-9914-4d09-da44-d6dded2342e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","\"get_similar_work_items\": \n","    {\n","        \"work_id\": \"don:core:dvrv-us-1:devo/0:issue/1\"\n","    },\n","\"summarize_objects\": \n","    {\n","        \"objects\": \"$$PREV[0]\"\n","    }\n","}\n","\n","\n","{\n","  \"works_list\": {\n","    \"issue.priority\": [\"P0\"],\n","    \"owned_by\": [\"Harry\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"$$PREV[1]\"]\n","  }\n","}\n","\n","\n"]}]},{"cell_type":"code","source":["''' Now, we have 3 lists: queries, tool_results and argument_predictions.\n","We can summarize them into a CSV '''\n","data={'query':queries, 'tools':tool_results, 'arguments':argument_predictions}\n","df=pd.DataFrame(data)\n","df.to_csv('resultIB06.csv')"],"metadata":{"id":"TjlrSVgfEfTl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_json_schema(cell_value):\n","    prompt = \"\"\"Convert the following argument cell value to the general JSON schema. If there are specific fields not present. Ignore them.\n","                  general JSON schema (results may be different):\n","                  [\n","                    \"tool_name\": \"tool_name\",\n","                    \"arguments\": [\n","                      {\n","                        \"argument_name\":\"arg_name\"\n","                        \"argument_value\":\"arg_value\"\n","                      }\n","                    ]\n","                  ]\n","\n","                  An example:\n","                  [\n","                    {\n","                      \"tool_name\": \"whoami\",\n","                      \"arguments\": []\n","                    },\n","                    {\n","                      \"tool_name\": \"works_list\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"issue.priority\",\n","                          \"argument_value\": [\"p0\"]\n","                        },\n","                        {\n","                          \"argument_name\": \"owned_by\",\n","                          \"argument_value\": [\"$$PREV[0]\"]\n","                        },\n","                        {\n","                          \"argument_name\": \"type\",\n","                          \"argument_value\": [\"issue\"]\n","                        }\n","                      ]\n","                    },\n","                    {\n","                      \"tool_name\": \"prioritize_objects\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"objects\",\n","                          \"argument_value\": \"$$PREV[1]\"\n","                        }\n","                      ]\n","                    },\n","                    {\n","                      \"tool_name\": \"get_sprint_id\",\n","                      \"arguments\": []\n","                    },\n","                    {\n","                      \"tool_name\": \"add_work_items_to_sprint\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"work_ids\",\n","                          \"argument_value\": \"$$PREV[2]\"\n","                        },\n","                        {\n","                          \"argument_name\": \"sprint_id\",\n","                          \"argument_value\": \"$$PREV[3]\"\n","                        }\n","                      ]\n","                    }\n","                ]\"\"\"\n","    messages=[{\n","      \"role\":\"user\",\n","      \"content\":prompt\n","  }]\n","\n","    response=openai.ChatCompletion.create(\n","      model=model,\n","      messages=messages,\n","      temperature=0\n","  )\n","    generated_json_schema = response.choices[0].message['content']\n","\n","    return generated_json_schema\n","\n","csv_file_path = '/content/resultIB06_base.csv'\n","df = pd.read_csv(csv_file_path)\n","\n","df['generated_json_schema'] = df['arguments'].apply(generate_json_schema)\n","\n","output_csv_path = 'output_file.csv'\n","df.to_csv(output_csv_path, index=False)"],"metadata":{"id":"BYu8SIFga-Pc"},"execution_count":null,"outputs":[]}]}