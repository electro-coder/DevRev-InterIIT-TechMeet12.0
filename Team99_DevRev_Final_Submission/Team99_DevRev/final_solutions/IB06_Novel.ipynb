{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Hi_3GrtnQwI","outputId":"4d8a60dc-2c1b-429c-8651-793adaad1865","executionInfo":{"status":"ok","timestamp":1702296975445,"user_tz":-330,"elapsed":20538,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n","Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n","Mon Dec 11 12:16:00 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already satisfied: ctransformers in /usr/local/lib/python3.10/dist-packages (0.2.27)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from ctransformers) (0.19.4)\n","Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (4.5.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->ctransformers) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->ctransformers) (2023.11.17)\n"]}],"source":["''' This notebook contains the following:\n","    M1 - GPT 3.5 Finetuned on the new tool prompts\n","    M2 - GPT 4\n","\n","    Following tools have been added:\n","    'get_previous_sprint':'Returns the sprint id of the previous sprint',\n","    'return_top_k_items':'Returns the top k items from the given list of items',\n","'''\n","!pip install openai==0.28\n","!nvidia-smi\n","!pip install pandas\n","!CT_CUBLAS=1 pip install ctransformers --no-binary ctransformers"]},{"cell_type":"code","source":["!pip install accelerate\n","!pip install -U git+https://github.com/huggingface/accelerate.git"],"metadata":{"id":"92ZS1oVUnXGY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702297001961,"user_tz":-330,"elapsed":26534,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"418a7890-7829-4fa6-9aeb-9442760df5a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.25.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Collecting git+https://github.com/huggingface/accelerate.git\n","  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-gwgh6nfc\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-gwgh6nfc\n","  Resolved https://github.com/huggingface/accelerate.git to commit 694f2e2c12efbda81a1aa4b4b486767264116a2f\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (2.1.0+cu118)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.25.0.dev0) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0.dev0) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.25.0.dev0) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.25.0.dev0) (1.3.0)\n","Building wheels for collected packages: accelerate\n","  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for accelerate: filename=accelerate-0.25.0.dev0-py3-none-any.whl size=267070 sha256=906af20a87fab2bd21de53f968dac477b28adcb4b0220bad5be224542e9d421e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-led_4pdh/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n","Successfully built accelerate\n","Installing collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.25.0\n","    Uninstalling accelerate-0.25.0:\n","      Successfully uninstalled accelerate-0.25.0\n","Successfully installed accelerate-0.25.0.dev0\n"]}]},{"cell_type":"code","source":["!pip install pytorch-pretrained-bert\n","import pytorch_pretrained_bert as ppb\n","assert 'bert-large-cased' in ppb.modeling.PRETRAINED_MODEL_ARCHIVE_MAP"],"metadata":{"id":"Kcf7JIICoiPJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702297010758,"user_tz":-330,"elapsed":8816,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"3651ddf4-c070-4a10-aba5-36b06b50be41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.10/dist-packages (0.6.2)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.1.0+cu118)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.23.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (1.33.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (4.66.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from pytorch-pretrained-bert) (2023.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.1.0)\n","Requirement already satisfied: botocore<1.34.0,>=1.33.11 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.33.11)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\n","Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from boto3->pytorch-pretrained-bert) (0.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pytorch-pretrained-bert) (2023.11.17)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.0,>=1.33.11->boto3->pytorch-pretrained-bert) (2.8.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.11->boto3->pytorch-pretrained-bert) (1.16.0)\n"]}]},{"cell_type":"code","source":["!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n","!pip install -q datasets bitsandbytes einops wandb"],"metadata":{"id":"6_lJl9DdomgC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702297045802,"user_tz":-330,"elapsed":35049,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"d0de935f-c012-43d1-94c5-609c35496ef4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import openai\n","import os\n","import pandas as pd"],"metadata":{"id":"RoGX6DrUornK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sheet_id = \"1N8oZ6XYKFeWbAwTr13yCSxbKu6eo-iKsYH3-IJ5Uuuk\"\n","sheet_name = \"Sheet1\"\n","url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\""],"metadata":{"id":"74sOfxmXd29h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.read_csv(url)"],"metadata":{"id":"aAeUhx00etES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["queries=[] # This list will contain the list of all queries\n","for query in df['Prompt']:\n","  queries.append(query)"],"metadata":{"id":"yhI_GSeBuItq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["openai.api_key=\"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\"\n","model1=\"ft:gpt-3.5-turbo-0613:devrev-inter-iit-tech-meet::8UUzm0Kh\""],"metadata":{"id":"zwHWZGeupY3A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_tools(query):\n","  system_prompt = \"\"\" Find the tools that would be useful to answer the following query. The available tools and their uses are as follows:\n","  [\n","    'works_list':'returns a list of work-items matching the request',\n","    'summarize_objects':'summarizes a list of objects',\n","    'prioritize_objects':'sorts a list of objects by priority',\n","    'add_work_items_to_sprint':'Adds given work items to a sprint',\n","    'get_sprint_id':'Returns id of the current sprint',\n","    'get_similar_work_items':'Returns work items similar to the given work item',\n","    'search_object_by_name':'given a string, returns id of a matching object',\n","    'create_actionable_tasks_from_text':'Given a text, extracts actionable tasks',\n","    'who_am_i':'Returns id of the current user',\n","  ]\n","  Your answer should only compose of one or more of these tools. Any extra tool or text will be penalized. Return the tools enclosed in [ ].\n","  Given query is \"\"\"\n","\n","  user_prompt = f\"\"\": {query} : \"\"\"\n","\n","  final_prompt = system_prompt + \"\\n\" + user_prompt\n","  messages=[{\n","      \"role\":\"user\",\n","      \"content\":final_prompt\n","  }]\n","\n","  responses=openai.ChatCompletion.create(\n","      model=model1,\n","      messages=messages,\n","      temperature=0\n","  )\n","\n","  return responses.choices[0].message['content']"],"metadata":{"id":"_NiKiGf4ot_w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tool_results=[]\n","for query in queries:\n","  input_string=get_tools(query)\n","  tool_results.append(input_string)"],"metadata":{"id":"46lTaUffpsOt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Conversion of string to list:\n","def convert_string_to_list(string):\n","  \"\"\"\n","  Converts a string in the format of a list to a list of strings.\n","\n","  Args:\n","    string: The string to convert.\n","\n","  Returns:\n","    A list of strings.\n","  \"\"\"\n","  # Remove any leading and trailing spaces\n","  string = string.strip()\n","\n","  # Check if the string starts and ends with square brackets\n","  if not string.startswith('[') or not string.endswith(']'):\n","    raise ValueError('Invalid string format. Expected format: [item1, item2, ...]')\n","\n","  # Remove the square brackets\n","  string = string[1:-1]\n","\n","  # Split the string by commas and strip any whitespace around each item\n","  items = [item.strip() for item in string.split(',')]\n","\n","  return items"],"metadata":{"id":"401kg-RvqP7S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def analyze_query(tools_list, query_text):\n","    tools_purpose = {\n","        'works_list': 'Returns a list of objects matching the request',\n","        'summarize_objects': 'Summarizes a list of objects',\n","        'prioritize_objects': 'Returns a list of objects sorted by priority',\n","        'add_work_items_to_sprint':'Adds the given objects to the sprint',\n","        'get_sprint_id':'Return the id of the current sprint',\n","        'get_similar_work_items':'Returns a list of objects that are similar to the given object',\n","        'search_object_by_name':'Given a search string, returns the id of a matching object in the system of record',\n","        'create_actionable_tasks_from_text':'Given a text, extracts actionable text The text from which the actionable string insights, and creates tasks for them, which are kind of a work item',\n","        'who_am_i':'Returns string_id of current user',\n","        # 'get_previous_sprint':'Returns the sprint id of the previous sprint',\n","        # 'return_top_k_items':'Returns the top k items from the given list of items',\n","    }\n","\n","    tools_arguments = {\n","        'works_list': ['applies_to_part: Array of strings to filter works relevant to', 'created_by: Takes array of strings and filters work created by users in the array', 'issue.priority: Array of strings to filter issues with given priorites in the array', 'issue.rev_orgs: Array of strings to filter issues for the organizations provided in the array', 'limit: integer providing the maximum number of works to return', 'owned_by: Array of strings to filter issues owned by users specified in the array', 'stage.name: Array of strings to filter work in the stages provided in the array', 'ticket.needs_response: Boolean value telling if a ticket needs a response','ticket.rev_org: Array of strings to return tickets associated with the given strings', 'ticket.severity: Array of strings to filter issues with given severity in the array', 'ticket.source_channel: Array of strings to filter for ticklets of the provided channels in the array', 'type: Array of strings with allowed values: [issue, ticket, task] Filters for work of the provided types' ],\n","        'summarize_objects': ['objects: List of object ids to summarize'],\n","        'prioritize_objects': ['objects: List of objects to prioritize'],\n","        'add_work_items_to_sprint': ['work_ids: List of objects to be added', 'sprint_id: Id of the sprint'],\n","        'get_sprint_id': [],\n","        'get_similar_work_items': ['work_id: id of work item to find similar items to'],\n","        'search_object_by_name': ['query: String to search for'],\n","        'create_actionable_tasks_from_text': ['text: Text to create actionable tasks from'],\n","        'who_am_i': [],\n","        # 'get_previous_sprint':[],\n","        # 'return_top_k_items':['objects: List of objects sorted by priority', 'k: Number of items to be returned']\n","    }\n","\n","    relevant_purposes = {tool: tools_purpose[tool] for tool in tools_list if tool in tools_purpose}\n","    relevant_arguments = {tool: tools_arguments[tool] for tool in tools_list if tool in tools_arguments}\n","\n","    output_string = f\"The given query utilizes the following tools: {tools_list}. \"\n","    output_string += f\"The arguments of the tools and their description  is as follows. Format is 'argument_name:Purpose of argument': {relevant_arguments}. \"\n","    output_string += f\"The purpose of the tools is as follows: {relevant_purposes}. \"\n","    output_string +=\"Note that the words issues, objects and work_items have been used interchangably\"\n","    output_string += f\"Find the values arguments for the given tools from the following text:\\\\ {query_text} \\\\\"\n","    output_string += \"Just return the value of the arguments, do not return anything else. In case you need to use the output of the previous tool as an input to the next tool, you can name it as $$PREV[i], where i is the index of the tool starting from 0. Return answer in nested JSON format with separate JSONS in one JSON for each tool named after the tool itself. The keys are: argument_name and argument_value. Every argument need not have a value. But every tool taking an argument must take atleast one argument. Only find values for relevant arguments.\"\n","\n","    return output_string"],"metadata":{"id":"EDtsSJ01q1Hd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arg_prompts=[]\n","for i in range(0,len(tool_results)):\n","  # convert string to list of tools\n","  tools_list=convert_string_to_list(tool_results[i])\n","  final_prompt=analyze_query(tools_list,queries[i]);\n","  arg_prompts.append(final_prompt)"],"metadata":{"id":"MDVbii9RrBim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model2 = \"gpt-4\""],"metadata":{"id":"JSYzLtjWoTWt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_arguments(formatted_prompt):\n","  messages=[{\n","      \"role\":\"user\",\n","      \"content\":formatted_prompt\n","  }]\n","\n","  responses=openai.ChatCompletion.create(\n","      model=model2,\n","      messages=messages,\n","      temperature=0\n","  )\n","\n","  return responses.choices[0].message['content']"],"metadata":{"id":"jOEng54krVim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["argument_predictions=[]\n","for prompt in arg_prompts:\n","  arg=get_arguments(prompt);\n","  argument_predictions.append(arg)"],"metadata":{"id":"TiHlwGS-rgSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for arg in argument_predictions:\n","  print(arg)\n","  print('\\n')"],"metadata":{"id":"AC2Ue00ewvi0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702297418981,"user_tz":-330,"elapsed":21,"user":{"displayName":"CS21B059 JONNALAGADDA CHANDRADITHYA SASTRY","userId":"00121086050964175351"}},"outputId":"754660f0-2a88-4feb-dce0-ddc75b9500a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","\"get_similar_work_items\": \n","    {\n","        \"work_id\": \"don:core:dvrv-us-1:devo/0:issue/1\"\n","    },\n","\"summarize_objects\": \n","    {\n","        \"objects\": \"$$PREV[0]\"\n","    }\n","}\n","\n","\n","{\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"owned_by\",\n","      \"argument_value\": [\"Jane Doe\"]\n","    },\n","    {\n","      \"argument_name\": \"type\",\n","      \"argument_value\": [\"user story\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[0]\"]\n","    }\n","  ]\n","}\n","\n","\n","The text does not provide enough specific information to extract values for the arguments of the given tools.\n","\n","\n","{\n","  \"get_sprint_id\": {},\n","  \"works_list\": {\n","    \"applies_to_part\": [\"Security\"],\n","    \"type\": [\"issue\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[1]\"]\n","  },\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": [\"$$PREV[2]\"]\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"applies_to_part\",\n","      \"argument_value\": [\"UI/UX\"]\n","    },\n","    {\n","      \"argument_name\": \"type\",\n","      \"argument_value\": [\"task\"]\n","    },\n","    {\n","      \"argument_name\": \"stage.name\",\n","      \"argument_value\": [\"current sprint\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[0]\"]\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"DEV\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": \"$$PREV[0]\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"applies_to_part\",\n","      \"argument_value\": [\"Internal\"]\n","    },\n","    {\n","      \"argument_name\": \"stage.name\",\n","      \"argument_value\": [\"current spring backlog\"]\n","    },\n","    {\n","      \"argument_name\": \"type\",\n","      \"argument_value\": [\"task\"]\n","    }\n","  ],\n","  \"prioritize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[0]\"]\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"argument_name\": \"text\",\n","    \"argument_value\": \"Given a customer transcript \\\"text\\\", create work items, add them to the current sprint, summarize and prioritize them\"\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"argument_name\": [\"work_ids\", \"sprint_id\"],\n","    \"argument_value\": [\"$$PREV[0]\", \"$$PREV[1]\"]\n","  },\n","  \"summarize_objects\": {\n","    \"argument_name\": \"objects\",\n","    \"argument_value\": \"$$PREV[2]\"\n","  },\n","  \"prioritize_objects\": {\n","    \"argument_name\": \"objects\",\n","    \"argument_value\": \"$$PREV[3]\"\n","  }\n","}\n","\n","\n","{\"get_similar_work_items\": {\"argument_name\": \"work_id\", \"argument_value\": \"user/ref:issue\"}, \"summarize_objects\": {\"argument_name\": \"objects\", \"argument_value\": \"$$PREV[0]\"}}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"argument_name\": \"query\",\n","    \"argument_value\": \"P0 for user Harry\"\n","  },\n","  \"summarize_objects\": {\n","    \"argument_name\": \"objects\",\n","    \"argument_value\": \"$$PREV[0]\"\n","  },\n","  \"prioritize_objects\": {\n","    \"argument_name\": \"objects\",\n","    \"argument_value\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"argument_name\": \"query\",\n","    \"argument_value\": \"Mark\"\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"argument_name\": [\"work_ids\", \"sprint_id\"],\n","    \"argument_value\": [\"$$PREV[0]\", \"$$PREV[1]\"]\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"argument_name\": \"query\",\n","    \"argument_value\": \"SigmaSquad\"\n","  },\n","  \"prioritize_objects\": {\n","    \"argument_name\": \"objects\",\n","    \"argument_value\": \"$$PREV[0]\"\n","  }\n","}\n","\n","\n","The values for the arguments would be:\n","\n","```\n","{\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"created_by\",\n","      \"argument_value\": [\"I\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[0]\"]\n","    }\n","  ]\n","}\n","```\n","\n","\n","{\n","  \"search_object_by_name\": [],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"stage.name\",\n","      \"argument_value\": [\"triage\"]\n","    },\n","    {\n","      \"argument_name\": \"issue.rev_orgs\",\n","      \"argument_value\": [\"Ajin\", \"Kalidas\"]\n","    },\n","    {\n","      \"argument_name\": \"issue.priority\",\n","      \"argument_value\": [\"P0\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[1]\"]\n","    }\n","  ],\n","  \"prioritize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[2]\"]\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Given the text T detailing the recent team meeting, create a list of tasks.\"\n","  },\n","  \"works_list\": {\n","    \"ticket.source_channel\": [\"discord\"],\n","    \"created_by\": [\"Raja\"]\n","  },\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": \"$$PREV[0]\",\n","    \"sprint_id\": \"current sprint\"\n","  }\n","}\n","\n","\n","{\n","  \"get_sprint_id\": [\n","    {\n","      \"argument_name\": \"\",\n","      \"argument_value\": \"\"\n","    }\n","  ],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"applies_to_part\",\n","      \"argument_value\": [\"Backend\"]\n","    },\n","    {\n","      \"argument_name\": \"type\",\n","      \"argument_value\": [\"task\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": \"$$PREV[1]\"\n","    }\n","  ],\n","  \"prioritize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": \"$$PREV[2]\"\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Delve into the cosmic ponderings: Explore and compare diverse cultural and scientific perspectives on the question, \\\"What is the nature of existence?\\\"\"\n","  },\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"$$PREV[0]\"\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"BUG-456\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": \"$$PREV[0]\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": [\n","    {\n","      \"argument_name\": \"query\",\n","      \"argument_value\": \"REV(customer) N V\"\n","    }\n","  ],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"issue.rev_orgs\",\n","      \"argument_value\": [\"$$PREV[0]\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[1]\"]\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"works_list\": [],\n","  \"create_actionable_tasks_from_text\": [\n","    {\n","      \"argument_name\": \"text\",\n","      \"argument_value\": \"Analyze the minutes from the latest team meeting, generate a task list\"\n","    }\n","  ],\n","  \"get_sprint_id\": [],\n","  \"add_work_items_to_sprint\": [\n","    {\n","      \"argument_name\": \"work_ids\",\n","      \"argument_value\": \"$$PREV[1]\"\n","    },\n","    {\n","      \"argument_name\": \"sprint_id\",\n","      \"argument_value\": \"$$PREV[2]\"\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"search_object_by_name\": [\n","    {\n","      \"argument_name\": \"query\",\n","      \"argument_value\": \"Analytics\"\n","    }\n","  ],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"applies_to_part\",\n","      \"argument_value\": \"$$PREV[0]\"\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": \"$$PREV[1]\"\n","    }\n","  ],\n","  \"prioritize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": \"$$PREV[2]\"\n","    }\n","  ]\n","}\n","\n","\n","The text does not provide any values for the arguments of the mentioned tools.\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"argument_name\": \"query\",\n","    \"argument_value\": \"high-impact tickets originating from Microsoft Teams from customer Rahul\"\n","  },\n","  \"get_similar_work_items\": {\n","    \"argument_name\": \"work_id\",\n","    \"argument_value\": \"$$PREV[0]\"\n","  },\n","  \"summarize_objects\": {\n","    \"argument_name\": \"objects\",\n","    \"argument_value\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": [\n","    {\n","      \"argument_name\": \"text\",\n","      \"argument_value\": \"Contemplate the meaning of knowledge\"\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"who_am_i\": [\n","    {\n","      \"argument_name\": \"\",\n","      \"argument_value\": \"\"\n","    }\n","  ],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"created_by\",\n","      \"argument_value\": [\"$$PREV[0]\"]\n","    },\n","    {\n","      \"argument_name\": \"ticket.severity\",\n","      \"argument_value\": [\"high\"]\n","    },\n","    {\n","      \"argument_name\": \"type\",\n","      \"argument_value\": [\"ticket\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[1]\"]\n","    }\n","  ]\n","}\n","\n","\n","{\n","\"search_object_by_name\": {\n","\"argument_name\": \"query\",\n","\"argument_value\": \"urgent emails\"\n","},\n","\"prioritize_objects\": {\n","\"argument_name\": \"objects\",\n","\"argument_value\": \"$$PREV[0]\"\n","},\n","\"summarize_objects\": {\n","\"argument_name\": \"objects\",\n","\"argument_value\": \"$$PREV[1]\"\n","}\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"send an email to admin about the problems encountered during completion of tasks\"\n","  },\n","  \"search_object_by_name\": {\n","    \"query\": \"\"\n","  }\n","}\n","\n","\n","{\n","\"get_similar_work_items\": \n","    {\n","        \"work_id\": \"$$PREV[0]\"\n","    }, \n","\"search_object_by_name\": \n","    {\n","        \"query\": \"Null Pointer Exception in Module\"\n","    }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": {\n","    \"query\": \"Backend Refactoring\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": \"$$PREV[0]\"\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": \"$$PREV[1]\",\n","    \"sprint_id\": \"$$PREV[2]\"\n","  }\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Implement the payment gateway and test the checkout flow\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": \"$$PREV[0]\"\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": \"$$PREV[1]\",\n","    \"sprint_id\": \"$$PREV[2]\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": [\n","    {\n","      \"argument_name\": \"query\",\n","      \"argument_value\": \"API Development\"\n","    }\n","  ],\n","  \"get_similar_work_items\": [\n","    {\n","      \"argument_name\": \"work_id\",\n","      \"argument_value\": \"$$PREV[0]\"\n","    }\n","  ]\n","}\n","\n","\n","The text does not provide any specific values for the arguments of the tools. Therefore, it is not possible to extract any argument values from the given text.\n","\n","\n","The text does not provide any values for the arguments of the tools 'get_similar_work_items' and 'summarize_objects'.\n","\n","\n","The text does not provide any specific values that can be used as arguments for the given tools.\n","\n","\n","{\n","  \"works_list\": {\n","    \"applies_to_part\": [\"INS69\"]\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": [\"$$PREV[0]\"]\n","  },\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": [\"$$PREV[1]\"]\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": [\n","    {\n","      \"argument_name\": \"query\",\n","      \"argument_value\": \"Navishkar\"\n","    }\n","  ],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"applies_to_part\",\n","      \"argument_value\": \"$$PREV[0]\"\n","    }\n","  ],\n","  \"prioritize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": \"$$PREV[1]\"\n","    }\n","  ],\n","  \"get_sprint_id\": [],\n","  \"add_work_items_to_sprint\": [\n","    {\n","      \"argument_name\": \"work_ids\",\n","      \"argument_value\": \"$$PREV[2]\"\n","    },\n","    {\n","      \"argument_name\": \"sprint_id\",\n","      \"argument_value\": \"$$PREV[3]\"\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"search_object_by_name\": [],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"ticket.severity\",\n","      \"argument_value\": [\"blocker\"]\n","    },\n","    {\n","      \"argument_name\": \"issue.priority\",\n","      \"argument_value\": [\"P0\"]\n","    },\n","    {\n","      \"argument_name\": \"issue.rev_orgs\",\n","      \"argument_value\": [\"Llama\", \"Falcon\"]\n","    },\n","    {\n","      \"argument_name\": \"type\",\n","      \"argument_value\": [\"ticket\", \"issue\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[1]\"]\n","    }\n","  ],\n","  \"prioritize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": [\"$$PREV[2]\"]\n","    }\n","  ]\n","}\n","\n","\n","{\"get_similar_work_items\": {\"argument_name\": \"work_id\", \"argument_value\": \"Finetuning GPT-3.5-Turbo\"}, \"summarize_objects\": {\"argument_name\": \"objects\", \"argument_value\": \"$$PREV[0]\"}}\n","\n","\n","{\n","  \"who_am_i\": [],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"owned_by\",\n","      \"argument_value\": [\"$$PREV[0]\"]\n","    },\n","    {\n","      \"argument_name\": \"type\",\n","      \"argument_value\": [\"task\"]\n","    }\n","  ],\n","  \"get_sprint_id\": [],\n","  \"add_work_items_to_sprint\": [\n","    {\n","      \"argument_name\": \"work_ids\",\n","      \"argument_value\": [\"$$PREV[1]\"]\n","    },\n","    {\n","      \"argument_name\": \"sprint_id\",\n","      \"argument_value\": [\"$$PREV[2]\"]\n","    }\n","  ],\n","  \"search_object_by_name\": [\n","    {\n","      \"argument_name\": \"query\",\n","      \"argument_value\": [\"URGENT\"]\n","    }\n","  ]\n","}\n","\n","\n","{\n","  \"create_actionable_tasks_from_text\": {\n","    \"text\": \"Send an email to the IT department detailing recent technical challenges faced during project completion and request assistance.\"\n","  },\n","  \"works_list\": {}\n","}\n","\n","\n","The text does not provide enough information to extract values for the arguments of the mentioned tools 'search_object_by_name' and 'works_list'.\n","\n","\n","{\n","  \"summarize_objects\": {\n","    \"objects\": \"P1 issues\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": \"$$PREV[0]\"\n","  },\n","  \"get_sprint_id\": {},\n","  \"add_work_items_to_sprint\": {\n","    \"work_ids\": \"$$PREV[1]\",\n","    \"sprint_id\": \"$$PREV[2]\"\n","  }\n","}\n","\n","\n","{\n","  \"search_object_by_name\": [],\n","  \"works_list\": [\n","    {\n","      \"argument_name\": \"ticket.source_channel\",\n","      \"argument_value\": [\"Microsoft Team\", \"Zoom\"]\n","    },\n","    {\n","      \"argument_name\": \"type\",\n","      \"argument_value\": [\"task\"]\n","    }\n","  ],\n","  \"summarize_objects\": [\n","    {\n","      \"argument_name\": \"objects\",\n","      \"argument_value\": \"$$PREV[1]\"\n","    }\n","  ],\n","  \"add_work_items_to_sprint\": [\n","    {\n","      \"argument_name\": \"work_ids\",\n","      \"argument_value\": \"$$PREV[2]\"\n","    }\n","  ]\n","}\n","\n","\n","The text does not provide any information related to the tools or their arguments. Therefore, it's not possible to extract any values for the arguments of the tools from the text.\n","\n","\n","The text does not provide any information related to the tools or their arguments. Therefore, it's not possible to extract any values for the arguments of the tools from the given text.\n","\n","\n","{\n","  \"summarize_objects\": {\n","    \"objects\": [\"Pinnacle\", \"Skyward\"]\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": [\"Pinnacle\", \"Skyward\"]\n","  },\n","  \"search_object_by_name\": {\n","    \"query\": [\"Pinnacle\", \"Skyward\"]\n","  }\n","}\n","\n","\n","{\n","  \"get_similar_work_items\": {\n","    \"work_id\": \"User Story:123\"\n","  },\n","  \"prioritize_objects\": {\n","    \"objects\": \"$$PREV[0]\"\n","  },\n","  \"summarize_objects\": {\n","    \"objects\": \"$$PREV[1]\"\n","  }\n","}\n","\n","\n","The text does not provide enough specific information to extract the values for the arguments of the given tools.\n","\n","\n"]}]},{"cell_type":"code","source":["''' Now, we have 3 lists: queries, tool_results and argument_predictions.\n","We can summarize them into a CSV '''\n","data={'query':queries, 'tools':tool_results, 'arguments':argument_predictions}\n","df=pd.DataFrame(data)\n","df.to_csv('resultFinetunedIB06_base.csv')"],"metadata":{"id":"M3lwFpFcvxAZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate_json_schema(cell_value):\n","    prompt = \"\"\"Convert the following argument cell value to the general JSON schema. If there are specific fields not present. Ignore them.\n","                  general JSON schema (results may be different):\n","                  [\n","                    \"tool_name\": \"tool_name\",\n","                    \"arguments\": [\n","                      {\n","                        \"argument_name\":\"arg_name\"\n","                        \"argument_value\":\"arg_value\"\n","                      }\n","                    ]\n","                  ]\n","\n","                  An example:\n","                  [\n","                    {\n","                      \"tool_name\": \"whoami\",\n","                      \"arguments\": []\n","                    },\n","                    {\n","                      \"tool_name\": \"works_list\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"issue.priority\",\n","                          \"argument_value\": [\"p0\"]\n","                        },\n","                        {\n","                          \"argument_name\": \"owned_by\",\n","                          \"argument_value\": [\"$$PREV[0]\"]\n","                        },\n","                        {\n","                          \"argument_name\": \"type\",\n","                          \"argument_value\": [\"issue\"]\n","                        }\n","                      ]\n","                    },\n","                    {\n","                      \"tool_name\": \"prioritize_objects\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"objects\",\n","                          \"argument_value\": \"$$PREV[1]\"\n","                        }\n","                      ]\n","                    },\n","                    {\n","                      \"tool_name\": \"get_sprint_id\",\n","                      \"arguments\": []\n","                    },\n","                    {\n","                      \"tool_name\": \"add_work_items_to_sprint\",\n","                      \"arguments\": [\n","                        {\n","                          \"argument_name\": \"work_ids\",\n","                          \"argument_value\": \"$$PREV[2]\"\n","                        },\n","                        {\n","                          \"argument_name\": \"sprint_id\",\n","                          \"argument_value\": \"$$PREV[3]\"\n","                        }\n","                      ]\n","                    }\n","                ]\"\"\"\n","    messages=[{\n","      \"role\":\"user\",\n","      \"content\":prompt\n","  }]\n","\n","    response=openai.ChatCompletion.create(\n","      model=model,\n","      messages=messages,\n","      temperature=0\n","  )\n","    generated_json_schema = response.choices[0].message['content']\n","\n","    return generated_json_schema\n","\n","csv_file_path = '/content/resultIB06_novel.csv'\n","df = pd.read_csv(csv_file_path)\n","\n","df['generated_json_schema'] = df['arguments'].apply(generate_json_schema)\n","\n","output_csv_path = 'output_file.csv'\n","df.to_csv(output_csv_path, index=False)"],"metadata":{"id":"XJLk3iSKv7Vr"},"execution_count":null,"outputs":[]}]}